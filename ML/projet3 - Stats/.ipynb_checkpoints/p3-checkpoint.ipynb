{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.1\n",
    "\n",
    "# 1) Those events are random because the test examples should be considered to be drawn at random.\n",
    "# Those events are mutually exclusive because they cannot both occur.\n",
    "# Two mutually exclusive events A and B cannot be independent provided that P(A)>0 and P(B)>0.\n",
    "\n",
    "# 2) 5\n",
    "\n",
    "# 3) 4.47\n",
    "\n",
    "# 4) 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example from slide (0.158, 0.442)\n",
      "Question 1: (0.841, 0.959)\n",
      "Question 2: (0.792, 0.928)\n",
      "Question 3: (0.013, 0.067)\n",
      "Question 4: Fisher exact p-value = 0.515\n"
     ]
    }
   ],
   "source": [
    "# Question 3.2\n",
    "import math\n",
    "# 1-2) 90/100, compute 95% confidence\n",
    "def confidence(p, zn, n):\n",
    "    term = zn*math.sqrt((p*(1-p)) / n)\n",
    "    return round(p - term, 3), round(p + term, 3)\n",
    "\n",
    "print(\"Example from slide\", confidence(0.30, 1.96, 40))\n",
    "print(\"Question 1:\", confidence(0.90, 1.96, 100))\n",
    "print(\"Question 2:\", confidence(0.86, 1.96, 100))\n",
    "\n",
    "# 3) No\n",
    "print(\"Question 3:\", confidence(0.04, 1.96, 200))\n",
    "\n",
    "# 4)\n",
    "from scipy import stats\n",
    "from pandas import *\n",
    "\n",
    "def fisher_pvalue(n, m1, m2):\n",
    "    table=[[m1, m2],[n-m1, n-m2]]\n",
    "    return round(stats.fisher_exact(table)[1], 3)\n",
    "# table=[[15, 18],[35, 32]] # Example from slide\n",
    "n = 100\n",
    "print(\"Question 4: Fisher exact p-value =\", fisher_pvalue(n, n*0.1, n*0.14))\n",
    "\n",
    "# 5) Significant ? No, too high p-value\n",
    "\n",
    "# 6) 908\n",
    "# for n in [150, 400, 750, 908]:\n",
    "#     print(fisher_pvalue(n, n*0.1, n*0.14))\n",
    "\n",
    "# 7) Xi, the test set accuracy computed on the i th set, is assumed to be distributed according ∼Uniform(min=0,max=1).\n",
    "# The quality measure is X¯=1k∑ki=1Xi.\n",
    "# The quality measure X¯ is approximately distributed according ∼Normal(μ,σ2k), with μ=0.5 and σ2=112.\n",
    "\n",
    "# 8) The quality measure is not well centered around the expected μ value, found in the previous question.\n",
    "# The variance decreases when the number of test sets increases.\n",
    "\n",
    "# 9) The quality measure X¯ would no longer be approximately normally distributed. The results are thus expected to be significantly different.\n",
    "\n",
    "# 10) No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: 0.64\n",
      "Question 2: (0.546, 0.734)\n",
      "Question 3:\n",
      "[0.58, 0.58, 0.61, 0.61, 0.61, 0.61, 0.61, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.65, 0.65, 0.65, 0.65, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.74, 0.74, 0.75]\n",
      "Mean test accuracy: 0.6674\n",
      "Question 4: (0.575, 0.76)\n",
      "    indiv_test_acc  CI_lower_bound  CI_upper_bound  mean_test_acc  \\\n",
      "0             0.64           0.546           0.734         0.6674   \n",
      "1             0.59           0.494           0.686         0.6191   \n",
      "2             0.62           0.525           0.715         0.6825   \n",
      "3             0.61           0.514           0.706         0.6718   \n",
      "4             0.63           0.535           0.725         0.6720   \n",
      "5             0.71           0.621           0.799         0.6109   \n",
      "6             0.61           0.514           0.706         0.5820   \n",
      "7             0.71           0.621           0.799         0.7273   \n",
      "8             0.67           0.578           0.762         0.7455   \n",
      "9             0.71           0.621           0.799         0.6854   \n",
      "10            0.73           0.643           0.817         0.6797   \n",
      "11            0.78           0.699           0.861         0.7410   \n",
      "12            0.64           0.546           0.734         0.6527   \n",
      "13            0.59           0.494           0.686         0.5620   \n",
      "14            0.73           0.643           0.817         0.7030   \n",
      "15            0.74           0.654           0.826         0.7699   \n",
      "16            0.68           0.589           0.771         0.6707   \n",
      "17            0.50           0.402           0.598         0.5523   \n",
      "18            0.79           0.710           0.870         0.7101   \n",
      "19            0.56           0.463           0.657         0.6227   \n",
      "\n",
      "    observed_lower_bound  observed_upper_bound  \n",
      "0                  0.575                 0.760  \n",
      "1                  0.524                 0.714  \n",
      "2                  0.591                 0.774  \n",
      "3                  0.580                 0.764  \n",
      "4                  0.580                 0.764  \n",
      "5                  0.515                 0.706  \n",
      "6                  0.485                 0.679  \n",
      "7                  0.640                 0.815  \n",
      "8                  0.660                 0.831  \n",
      "9                  0.594                 0.776  \n",
      "10                 0.588                 0.771  \n",
      "11                 0.655                 0.827  \n",
      "12                 0.559                 0.746  \n",
      "13                 0.465                 0.659  \n",
      "14                 0.613                 0.793  \n",
      "15                 0.687                 0.852  \n",
      "16                 0.579                 0.763  \n",
      "17                 0.455                 0.650  \n",
      "18                 0.621                 0.799  \n",
      "19                 0.528                 0.718  \n"
     ]
    }
   ],
   "source": [
    "# Question 3.3\n",
    "# Statiscal https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "# 1)\n",
    "from sklearn.tree import DecisionTreeClassifier    # Learning algo, without pruning !\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "CollegeTrain = pd.read_csv(\"CollegeTrain.csv\", index_col=0)\n",
    "CollegeTest = pd.read_csv(\"CollegeTest.csv\", index_col=0)\n",
    "def accuracy(pred, true):\n",
    "    well = 0\n",
    "    total = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == true[i]: \n",
    "            well += 1\n",
    "        total += 1\n",
    "    return well / total\n",
    "\n",
    "fracTrain = CollegeTrain.sample(frac=0.05, random_state=0)\n",
    "model = DecisionTreeClassifier(random_state=0).fit(fracTrain.drop(\"Outcome\", axis=1), fracTrain[\"Outcome\"])\n",
    "nTest = CollegeTest.sample(100, random_state=0)\n",
    "\n",
    "test_acc = accuracy(model.predict(nTest.drop(\"Outcome\", axis=1)), nTest[\"Outcome\"])\n",
    "print(\"Question 1:\", test_acc)\n",
    "\n",
    "# 2)\n",
    "def confidence(p, zn, n):\n",
    "    term = zn*math.sqrt((p*(1-p)) / n)\n",
    "    return round(p - term, 3), round(p + term, 3)\n",
    "\n",
    "print(\"Question 2:\", confidence(0.64, 1.96, 100))\n",
    "\n",
    "# 3) \n",
    "def accuracy(pred, true):\n",
    "    well = 0\n",
    "    total = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == true[i]: \n",
    "            well += 1\n",
    "        total += 1\n",
    "    return well / total\n",
    "\n",
    "fracTrain = CollegeTrain.sample(frac=0.05, random_state=0)\n",
    "model = DecisionTreeClassifier(random_state=0).fit(fracTrain.drop(\"Outcome\", axis=1), fracTrain[\"Outcome\"])\n",
    "\n",
    "test_accs = []\n",
    "for i in range(100):\n",
    "    nTest = CollegeTest.sample(100, random_state=i)\n",
    "    test_accs.append(accuracy(model.predict(nTest.drop(\"Outcome\", axis=1)), nTest[\"Outcome\"]))\n",
    "mean_test_acc = np.mean(test_accs)\n",
    "print(\"Question 3:\")\n",
    "print(sorted(test_accs))\n",
    "print(\"Mean test accuracy:\", mean_test_acc)\n",
    "\n",
    "# 4)\n",
    "print(\"Question 4:\", confidence(0.6674, 1.96, 100))\n",
    "\n",
    "# 5)\n",
    "frame = pd.DataFrame(columns = [\"indiv_test_acc\", \"CI_lower_bound\", \"CI_upper_bound\", \"mean_test_acc\", \"observed_lower_bound\", \"observed_upper_bound\"])\n",
    "for i in range(20):\n",
    "    fracTrain = CollegeTrain.sample(frac=0.05, random_state=i)\n",
    "    model = DecisionTreeClassifier(random_state=0).fit(fracTrain.drop(\"Outcome\", axis=1), fracTrain[\"Outcome\"])\n",
    "    nTest = CollegeTest.sample(100, random_state=i)\n",
    "    test_acc = accuracy(model.predict(nTest.drop(\"Outcome\", axis=1)), nTest[\"Outcome\"])\n",
    "    confi_1 = confidence(test_acc, 1.96, 100)\n",
    "    test_accs = []\n",
    "    for j in range(100):\n",
    "        nTest = CollegeTest.sample(100, random_state=(i+1)*j)\n",
    "        test_accs.append(accuracy(model.predict(nTest.drop(\"Outcome\", axis=1)), nTest[\"Outcome\"]))\n",
    "    mean_test_acc = np.mean(test_accs)\n",
    "    confi_100 = confidence(mean_test_acc, 1.96, 100)\n",
    "    row = {'indiv_test_acc': test_acc, 'CI_lower_bound': confi_1[0], 'CI_upper_bound': confi_1[1], 'mean_test_acc': mean_test_acc, 'observed_lower_bound':confi_100[0], 'observed_upper_bound':confi_100[1]}\n",
    "    frame = frame.append(row, ignore_index=True)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
