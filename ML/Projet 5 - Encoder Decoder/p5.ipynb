{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# pandas data frame\n",
    "train_df = pd.read_csv(\"ML-A5-2022_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"ML-A5-2022_test.csv\", index_col=0)\n",
    "\n",
    "# Function K-Fold validation\n",
    "def KF_validation(X, Y, model, K):\n",
    "    KF = KFold(n_splits=K, random_state=8, shuffle=True)\n",
    "    SUM = 0\n",
    "    for train_index, test_index in KF.split(X):\n",
    "        X_train, X_test = X.iloc[train_index][:], X.iloc[test_index][:]\n",
    "        Y_train, Y_test = Y.iloc[train_index][:], Y.iloc[test_index][:]\n",
    "        bcr = BCR_score(Y_test, model.fit(X_train, Y_train).predict(X_test)) # sample_weight=weight_compute(Y_train)\n",
    "        SUM += bcr\n",
    "    return SUM/K\n",
    "\n",
    "# Same as  balanced_accuracy_score(y_true, y_pred), Compute the BCR\n",
    "def BCR_score(y_true, y_pred):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_true[i] == -1):\n",
    "            if (y_pred[i] == -1):\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if (y_pred[i] == -1):\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    recall1 = (TP/(TP+FN) if TP+FN != 0 else 0)\n",
    "    recall2 = (TN/(FP+TN) if FP+TN != 0 else 0)\n",
    "    return (1/2)*(recall1 + recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>AADACL2</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>AARSP1</th>\n",
       "      <th>ABCA9-AS1</th>\n",
       "      <th>ABCB10P3</th>\n",
       "      <th>ABCB10P4</th>\n",
       "      <th>ABCB4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNRF3-AS1</th>\n",
       "      <th>ZP2</th>\n",
       "      <th>ZP4</th>\n",
       "      <th>ZPLD1</th>\n",
       "      <th>ZSCAN5C</th>\n",
       "      <th>ZSWIM2</th>\n",
       "      <th>ZSWIM5P1</th>\n",
       "      <th>ZSWIM5P2</th>\n",
       "      <th>ZSWIM5P3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9730 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A3GALT2  A4GNT  AADAC  AADACL2  AADAT  AARSP1  ABCA9-AS1  ABCB10P3  \\\n",
       "C-1      0.0    0.0    0.0      0.0    0.0     0.0        2.0       0.0   \n",
       "C-2      0.0    0.0    0.0      0.0    0.0     0.0        2.0       0.0   \n",
       "C-3      0.0    0.0    0.0      0.0    0.0     0.0        2.0       0.0   \n",
       "C-4      0.0    0.0    0.0      0.0    0.0     0.0        2.0       0.0   \n",
       "C-5      0.0    0.0    0.0      0.0    0.0     0.0        2.0       0.0   \n",
       "\n",
       "     ABCB10P4  ABCB4  ...  ZNRF3-AS1  ZP2  ZP4  ZPLD1  ZSCAN5C  ZSWIM2  \\\n",
       "C-1       0.0    0.0  ...        2.0  0.0  0.0    0.0      2.0     2.0   \n",
       "C-2       0.0    0.0  ...        2.0  0.0  0.0    0.0      2.0     2.0   \n",
       "C-3       0.0    0.0  ...        2.0  0.0  0.0    0.0      2.0     2.0   \n",
       "C-4       0.0    0.0  ...        2.0  0.0  0.0    0.0      2.0     2.0   \n",
       "C-5       0.0    0.0  ...        2.0  0.0  0.0    0.0      2.0     2.0   \n",
       "\n",
       "     ZSWIM5P1  ZSWIM5P2  ZSWIM5P3  label  \n",
       "C-1       0.0       0.0       0.0     -1  \n",
       "C-2       0.0       0.0       0.0     -1  \n",
       "C-3       0.0       0.0       0.0     -1  \n",
       "C-4       0.0       0.0       0.0     -1  \n",
       "C-5       0.0       0.0       0.0      1  \n",
       "\n",
       "[5 rows x 9730 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Only float (except label={-1, 1}): Didn't succeed to represent the intensity low / medium /... during\n",
    "# Delete all NaN (replace by 0.0 or 3.0 in OldString columns)\n",
    "label_encoder = preprocessing.LabelEncoder().fit([\"low\", \"medium\", \"high\", \"NaN\"])\n",
    "for feature in train_df.columns:\n",
    "    if train_df[feature].dtypes == \"object\":\n",
    "        train_df[feature] = label_encoder.transform(train_df[feature])\n",
    "        train_df[feature] = train_df[feature].astype(\"float\")\n",
    "        test_df[feature] = label_encoder.transform(test_df[feature])\n",
    "        test_df[feature] = test_df[feature].astype(\"float\")\n",
    "train_df = train_df.fillna(0.0)\n",
    "test_df = test_df.fillna(0.0)\n",
    "\n",
    "# Drop feature / columns that are not enough correlated with label\n",
    "cor = train_df.corr() # 31m de compilation\n",
    "bad_feature = []\n",
    "cor_thresh = 0.1\n",
    "for i in range(len(cor[\"label\"])):\n",
    "    if np.abs(cor[\"label\"][i]) < cor_thresh:\n",
    "        bad_feature.append(cor[\"label\"].index[i]) \n",
    "train_df = train_df.drop(bad_feature, axis=1)\n",
    "test_df = test_df.drop(bad_feature, axis=1)\n",
    "\n",
    "# Outlier removal: Doesn't work, delete all entries because too much feature\n",
    "# new_train_df = train_df[(np.abs(scipy.stats.zscore(train_df)) < 3).all(axis=1)]\n",
    "\n",
    "# Weight / Data augmenting: Done inside the model\n",
    "\n",
    "# Division of the dataset in X & Y\n",
    "Y_train = train_df.loc[:][\"label\"]\n",
    "X_train = train_df.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: 0.7706854543951407\n"
     ]
    }
   ],
   "source": [
    "# All Result of different model after their optimization\n",
    "\n",
    "# Gradient Boosting Classifier or Bootsing #O.65 # 0.61 avec 0.1 de threshold\n",
    "# print(\"GBC:\", KF_validation(X_train, Y_train, GradientBoostingClassifier(random_state=0, loss='deviance', learning_rate=10, n_estimators=500, max_depth=22, max_features=None), 10))\n",
    "\n",
    "# Random Forest: Recherche de 150m et ça a rien donné de plus de 0.57 so tant pis\n",
    "# print(\"RF:\", KF_validation(X_train, Y_train, RandomForestRegressor(max_depth=2, random_state=1), 10))\n",
    "\n",
    "# KNN\n",
    "# best score : 0.6276460781515677 avec les best params : {'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2, 'leaf_size': 5, 'n_neighbors': 5}\n",
    "# print(\"KNN:\", KF_validation(X_train, Y_train, KNeighborsRegressor(n_neighbors=2), 10))\n",
    "# 0.6258795345856644 de base, 0.6023951507943568 si 0.1 de threshold\n",
    "\n",
    "# RidgeClassifier 0.5896929196757389 {'alpha': 0.001, 'fit_intercept': True, 'normalize': True, 'class_weight': {-1: 0.2, 1: 0.8}}\n",
    "\n",
    "# LinearRegression 0.5006329113924051\n",
    "# print(\"Linear:\", KF_validation(X_train, Y_train, LinearRegression(), 10))\n",
    "\n",
    "# Naive Bayes: 0.810820296628652 avec 0.1 de threshold\n",
    "# print(\"Gaussian Naive Bayes:\", KF_validation(X_train, Y_train, GaussianNB(), 10))\n",
    "\n",
    "# Perceptron\n",
    "# 0.664 {'penalty': None, 'max_iter': 200, 'tol': 0.0001, 'eta0': 1.0}\n",
    "# print(\"Perceptron:\", KF_validation(X_train, Y_train, Perceptron(n_jobs=-1, random_state=0, class_weight={-1: 0.2, 1: 0.8}, penalty=None, max_iter=200, tol=0.0001, eta0=1.0), 10))\n",
    "\n",
    "# SVM:\n",
    "# 0.728 avec 0.1 de threshold\n",
    "# print(\"SVM\", KF_validation(X_train, Y_train, SVC(kernel='rbf', degree=16, C=5.0, gamma='auto', coef0=5.0, tol=0.1, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, class_weight={-1: 0.211, 1: 0.789}), 10))\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "# print(\"Logistic regression:\", KF_validation(X_train, Y_train, LogisticRegression(penalty='l2', tol=0.0001, C=1.0, solver='lbfgs', max_iter=20, n_jobs=-1, class_weight={-1: 0.211, 1: 0.789}), 10))\n",
    "# 0.7706854543951407 avec thresold de 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7643896091082294\n"
     ]
    }
   ],
   "source": [
    "# Computing The prediction for the BCR we will get on test set.\n",
    "KF = KFold(n_splits=3, random_state=8, shuffle=True)\n",
    "for train_index, test_index in KF.split(train_df):\n",
    "    X_train1, X_test1 = X_train.iloc[train_index][:], X_train.iloc[test_index][:]\n",
    "    Y_train1, Y_test1 = Y_train.iloc[train_index][:], Y_train.iloc[test_index][:]\n",
    "model = LogisticRegression(penalty='l2', tol=0.0001, C=1.0, solver='lbfgs', max_iter=20, n_jobs=-1, class_weight={-1: 0.211, 1: 0.789})\n",
    "y_pred = model.fit(X_train1, Y_train1).predict(X_test1)\n",
    "pred_BCR = BCR_score(Y_test1, y_pred)\n",
    "theo_BCR = KF_validation(X_train, Y_train, LogisticRegression(penalty='l2', tol=0.0001, C=1.0, solver='lbfgs', max_iter=20, n_jobs=-1, class_weight={-1: 0.211, 1: 0.789}), 10)\n",
    "BCR_prediction = (pred_BCR + theo_BCR)/2\n",
    "print(BCR_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "model = LogisticRegression(penalty='l2', tol=0.0001, C=1.0, solver='lbfgs', max_iter=20, n_jobs=-1, class_weight={-1: 0.211, 1: 0.789})\n",
    "y_pred = model.fit(X_train, Y_train).predict(test_df)\n",
    "prediction = pd.DataFrame(y_pred, index=test_df.index, columns=[\"Prediction\"]).to_csv('y_test.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
