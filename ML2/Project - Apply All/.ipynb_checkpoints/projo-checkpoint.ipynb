{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import scipy\n",
    "X1 = pd.read_csv(\"X1.csv\")\n",
    "Y1 = pd.read_csv(\"Y1.csv\", header=None, names=['weight'] )\n",
    "X2 = pd.read_csv(\"X2.csv\")\n",
    "\n",
    "X1 = X1.drop(\"Unnamed: 0\",axis=1)\n",
    "X2 = X2.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "# Confusion matrix of best model on our validation data\n",
    "# Given code that can be copy-pasted\n",
    "def score_weight_class(bmi_pred, bmi_true, low, high):\n",
    "    tol=1\n",
    "    vpred = (bmi_pred >= low-tol) & (bmi_pred < high+tol)\n",
    "    vtrue = (bmi_true >= low) & (bmi_true < high)\n",
    "    if vtrue.sum() == 0:\n",
    "        print(\"no true samples here\")\n",
    "        return 0\n",
    "    rmse = np.sqrt(((bmi_true[vtrue] - bmi_pred[vtrue]) ** 2).mean())\n",
    "    rmse = rmse/(high-low+tol)   # normalize rmse in interval\n",
    "    acc = (vpred & vtrue).sum()/vtrue.sum()\n",
    "    return rmse*(1-acc)\n",
    "\n",
    "def score_regression(ytrue, ypred, height):\n",
    "    bmi_pred = ypred/(height*height)\n",
    "    bmi_true = ytrue/(height*height)\n",
    "    \n",
    "    scores = []\n",
    "    for bmi_low, bmi_high in zip([0, 18.5, 25, 30], [18.5, 25, 30, 100]):\n",
    "        scores.append(score_weight_class(bmi_pred, bmi_true, low=bmi_low, high=bmi_high))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# # Display all data\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # print all data\n",
    "#     print(X2)\n",
    "\n",
    "# I. Faire un ptit truc pour transformer le Y de poids vers les classes de poids\n",
    "# II. Faire qu'on prédise les classes et pas le poids.\n",
    "# III. Tenter d'augmenter le dataset avec class imbalance (en copiant les samples des classes sous-rpz ? / autre)\n",
    "# IV. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Data Engineering\n",
    "# Step 1 : Re-encode : Make all values in integer\n",
    "# Gender : {0: Male, 1: Female}\n",
    "# family_history_with_overweight : {0 : no, 1 : yes}\n",
    "# FAVC : {0 : no, 1 : yes}\n",
    "# CAEC : {0 : no, 1 : Sometimes, 2 : Frequently, 3 : Always}\n",
    "# SMOKE : {0 : no, 1 : yes}\n",
    "# SCC : {0 : no, 1 : yes}\n",
    "# CALC : {0 : no, 1 : Sometimes, 2 : Frequently, 3 : Always}\n",
    "# MTRANS {0 : \"Bike\", 1 : \"Walking\", 2 : \"Public_Transportation\", 3 : \"Motorbike\", 4 : \"Automobile\"}\n",
    "\n",
    "le_gender = preprocessing.LabelEncoder().fit([\"Male\", \"Female\"])\n",
    "le_yesno = preprocessing.LabelEncoder().fit([\"no\", \"yes\"])\n",
    "le_freq = preprocessing.LabelEncoder().fit([\"no\", \"Sometimes\", \"Frequently\", \"Always\"]) \n",
    "le_transport = preprocessing.LabelEncoder().fit([\"Bike\", \"Walking\", \"Public_Transportation\", \"Motorbike\", \"Automobile\"])\n",
    "for categorical_feature, label_encoder in [(\"Gender\", le_gender), (\"family_history_with_overweight\", le_yesno), (\"FAVC\", le_yesno), (\"CAEC\", le_freq), (\"SMOKE\", le_yesno), (\"SCC\", le_yesno), (\"CALC\", le_freq), (\"MTRANS\", le_transport)]:\n",
    "    X1[categorical_feature] = label_encoder.transform(X1[categorical_feature])\n",
    "    X2[categorical_feature] = label_encoder.transform(X2[categorical_feature])\n",
    "    \n",
    "    X1[categorical_feature] = X1[categorical_feature].astype(\"float\")\n",
    "    X2[categorical_feature] = X2[categorical_feature].astype(\"float\")\n",
    "\n",
    "for i in [\"FAVC\", \"FCVC\", \"NCP\", \"CAEC\", \"SMOKE\", \"SCC\", \"FAF\", \"TUE\", \"CALC\"]:\n",
    "    X1 = X1.drop(i,axis=1)\n",
    "    \n",
    "coef_weight = []\n",
    "for i in range(len(X1[\"Age\"])):\n",
    "    weight_i = 1\n",
    "    if (15 <= X1[\"Age\"][i] < 37):\n",
    "        weight_i += 1\n",
    "    if (1.55 < X1[\"Height\"][i] < 1.85):\n",
    "        weight_i += 1\n",
    "    if (X1[\"MTRANS\"][i] == 1 or X1[\"MTRANS\"][i] == 2):\n",
    "        weight_i += 1\n",
    "    coef_weight.append(weight_i)\n",
    "\n",
    "# Data Augmenting laissé pour le moment.\n",
    "# data_augmenting = []\n",
    "# i = 0\n",
    "# temp = pd.dataframe()\n",
    "# while i < range(len(X1[\"Age\"])):\n",
    "#     for feat in [\"Gender\", \"Age\", \"Height\", \"family_history_with_overweight\", \"CH2O\", \"MTRANS\", \"weight\"]:\n",
    "        \n",
    "df = pd.concat([X1, Y1], axis=1)\n",
    "# df = df[(np.abs(scipy.stats.zscore(df)) < 3).all(axis=1)]\n",
    "\n",
    "# See correlation plot between feature and target\n",
    "def print_data(X, Y):    \n",
    "    fig=plt.figure(figsize=(10, 10), dpi=90)\n",
    "    n_feats = len(X.columns)\n",
    "    for i, feat in enumerate(X.columns):\n",
    "        plt.subplot(n_feats//3+1,3,i+1)\n",
    "        plt.scatter(X[feat],Y , s=10)\n",
    "        plt.title(feat)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# print_data(df.drop(\"weight\", axis=1), df[\"weight\"])\n",
    "    \n",
    "# See heatmap of correlation\n",
    "def heatmap(df):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    cor = df.corr()\n",
    "    sns.heatmap(cor, annot=True, cmap='PiYG', center=0, vmin = -0.4, vmax = 0.4) #cmap=plt.cm.Reds\n",
    "    plt.show()\n",
    "# heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "no true samples here\n",
      "0.13666589917486957 0.18616839715348907 0.20056301766097517 0.16360822275926076\n"
     ]
    }
   ],
   "source": [
    "#    Model  \n",
    "# Feature selection and model selection (statistical tests seen during other courses allowed too).\n",
    "# Explore the metaparameters space according to the time available.\n",
    "\n",
    "# K-Folding\n",
    "X1_np = df.drop(\"weight\", axis=1).to_numpy()\n",
    "Y1_np = df[\"weight\"].to_numpy()\n",
    "\n",
    "def KF_validation(X, Y, model, K, mse=2):    \n",
    "    KF = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "    SUM = 0\n",
    "    ite = 0\n",
    "    for train_index, test_index in KF.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        #weight_ite = coef_weight[0:ite*25].append(coef_weight[(ite+1)*25:249])\n",
    "        model.fit(X_train, Y_train) #,sample_weight=weight_ite)\n",
    "        if mse == 0:\n",
    "            SUM += mean_absolute_error(Y_test, model.predict(X_test))\n",
    "        elif mse == 1:\n",
    "            SUM += model.score(X_test, Y_test)\n",
    "        else: # mse==2\n",
    "            SUM += score_regression(Y_test, model.predict(X_test), X_test[:,2])\n",
    "        ite+=1\n",
    "    return SUM/K\n",
    "\n",
    "KF_LR = KF_validation(X1_np, Y1_np, LinearRegression(), 10)\n",
    "\n",
    "KF_MLP = KF_validation(X1_np, Y1_np, MLPRegressor(max_iter=1000), 10)\n",
    "\n",
    "KF_KNN = KF_validation(X1_np, Y1_np, KNeighborsRegressor(n_neighbors=1), 10)  # Remis à 1 car c'est KNN 1 qu'il faut faire ?\n",
    "\n",
    "KF_RF = KF_validation(X1_np, Y1_np, RandomForestRegressor(max_depth=2, random_state=1), 10)\n",
    "\n",
    "print(KF_LR, KF_MLP, KF_KNN, KF_RF)\n",
    "#0.34565997921242675 0.2388756036283703 0.1577997944915723 0.27733036766295954\n",
    "\n",
    "# Model fitting\n",
    "# reg = LinearRegression().fit(X1, Y1)\n",
    "# Y2_LR = reg.predict(X2)\n",
    "\n",
    "# regr = MLPRegressor(random_state=1, max_iter=1000).fit(X1, Y1)\n",
    "# Y2_MLP = regr.predict(X2)\n",
    "\n",
    "# neigh = KNeighborsRegressor(n_neighbors=10).fit(X1, Y1)\n",
    "# Y2_KNN = neigh.predict(X2)\n",
    "\n",
    "# rand_forest = RandomForestRegressor(max_depth=2, random_state=1).fit(X1, Y1)\n",
    "# Y2_RF = rand_forest.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62.8 58.3 50.7 70.9 63.3 76.6 77.9 75.5 46.  70. ]\n",
      "[62.2 59.  49.8 70.6 67.8 84.5 72.9 73.1 52.1 71.5]\n",
      "[68.6 69.4 62.9 77.8 61.7 65.1 77.4 65.3 56.  64.6]\n"
     ]
    }
   ],
   "source": [
    "#    Prediction\n",
    "# one line per prediction and no header, no quotation marks around your numbers either. \n",
    "# At the tail end of this file you will add an additional number which is the estimated performance of your model \n",
    "# on the unseen data.\n",
    "\n",
    "estimate = 0\n",
    "Y2_LR = np.append(Y2_LR, estimate)\n",
    "Y2_LR = np.around(Y2_LR, 1)\n",
    "prediction = pd.DataFrame(Y2_LR).to_csv('Y2.csv', index=False, header=False)\n",
    "\n",
    "estimate = 0\n",
    "Y2_MLP = np.append(Y2_MLP, estimate)\n",
    "Y2_MLP = np.around(Y2_MLP, 1)\n",
    "prediction = pd.DataFrame(Y2_MLP).to_csv('Y2.csv', index=False, header=False)\n",
    "\n",
    "estimate = 0\n",
    "Y2_KNN = np.append(Y2_KNN, estimate)\n",
    "Y2_KNN = np.around(Y2_KNN, 1)\n",
    "prediction = pd.DataFrame(Y2_KNN).to_csv('Y2.csv', index=False, header=False)\n",
    "\n",
    "estimate = 0\n",
    "Y2_RF = np.append(Y2_RF, estimate)\n",
    "Y2_RF = np.around(Y2_RF, 1)\n",
    "prediction = pd.DataFrame(Y2_RF).to_csv('Y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
